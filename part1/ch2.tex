% !TeX root = ../main.tex
\chapter{高性能计算}

从实现的角度来看，深度学习涉及使用大量数据执行繁重的计算。\keyterm{图形处理单元} (\keyterm{GPU}) 可以在经济实惠的硬件上运行此类计算，从而对该领域的成功发挥了至关重要的作用。

使用 GPU 的重要性，以及由此产生的对有效计算的技术限制，迫使该领域的研究不断平衡数学的合理性和新方法的可实施性。

\section{GPU、TPU 和批处理}\label{sec2.1}

图形处理单元最初是为实时图像合成而设计的，这需要高度并行的架构，而这种架构恰好非常适合深度模型。随着人工智能用途的增加，GPU 配备了专用的\keyterm{张量核心}，并且开发了深度学习专用芯片，例如谷歌的\keyterm{张量处理单元}（\keyterm{TPU}）。

GPU 拥有数千个并行单元和自己的快速内存。限制因素通常不是计算单元的数量，而是\keyterm{对内存的读写操作}。最慢的链接位于 CPU 内存和 GPU 内存之间，因此应避免跨设备复制数据。此外，GPU 本身的结构涉及多级\keyterm{缓存}，这些缓存容量更小但速度更快，并且应该组织计算以避免不同缓存之间的复制。

具体来说，就是通过将计算组织为完全适合 GPU 内存的\keyterm{样本批次}再通过并行处理来实现的。当操作器组合样本和模型参数时，两者都必须移动到实际计算单元附近的高速缓存中。分批进行仅允许复制模型参数一次，而不是为每个样本复制一次。实际上，GPU 处理适合内存的批次几乎与处理单个样本一样快。

标准 GPU 的理论\keyterm{峰值性能}为每秒 $10^{13}-10^{14}$ 次浮点运算 (\keyterm{FLOP})，其内存通常在 $8$ 到 $80$ GB 之间。标准 \keyterm{FP32} 采用 $32$ 位编码浮点数，但经验结果表明，使用 $16$ 位编码，甚至对某些操作数采用更低的编码，不会降低性能。

我们将在 \ref{sec3.7} 节中讨论深度架构的尺寸。

\section{张量}

GPU 与 PyTorch 或 JAX 等\keyterm{深度学习框架}通过将要处理的量组织为\keyterm{张量}来操作要处理的量，张量是沿多个离散轴排列的一系列标量。它们是 $\mathbb{R}^{N_1 \times \dots \times N_D}$ 的元素，泛化了向量和矩阵的概念。

张量用于表示要处理的信号、模型的\keyterm{可训练参数}以及它们计算的中间量。后者被称为\keyterm{激活}，指的是神经元激活。

例如，时间序列自然地被编码为 $T \times D$ 张量，或者，由于历史原因，编码为 $D \times T$ 张量，其中 $T$ 是其持续时间，$D$ 是每个时间帧特征表示的维度，通常称为\keyterm{通道}数。类似地，二维结构信号可以表示为 $D \times H \times W$ 张量，其中 $H$ 和 $W$ 是其高度和宽度。RGB 图像对应于 $D = 3$，但在大型模型中通道数可能会多至到数千个。

添加更多维度可以表示一系列对象。例如，$50$ 个分辨率为 $32 \times 24$ 的 RGB 图像可以编码为 $50 \times 3 \times 24 \times 32$ 张量。

深度学习库提供了大量操作，包括标准线性代数、复杂重塑和提取以及深度学习特定操作，其中一些我们将在第 \ref{ch4} 章中看到。张量的实现将形状表示与内存中系数的存储布局分开。这允许在不复制系数的情况下完成许多重塑、转置和提取操作，因此速度非常快。

在实践中，几乎任何计算都可以分解为基本张量运算，这避免了语言级别的非并行循环和不良的内存管理。

除了方便使用之外，张量还有助于提高计算效率。所有参与开发可操作深度模型的人员，从驱动程序、库和模型的设计者到计算机和芯片的设计者，都知道数据将作为张量进行操作。由此产生的对局部性和块可分解性的限制使该链条中的所有参与者都能给出最佳设计。